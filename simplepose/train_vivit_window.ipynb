{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import VivitConfig\n",
    "\n",
    "from model.vivit import VivitPose\n",
    "from preprocess_data import get_video_datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "device = 'cuda'\n",
    "configuration = VivitConfig()\n",
    "vivit_num_frames = 5\n",
    "configuration.num_labels = 201\n",
    "configuration.num_frames=vivit_num_frames\n",
    "model = VivitPose(configuration).to(device)\n",
    "train_data, test_data = get_video_datasets()\n",
    "train_loader = DataLoader(train_data, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear gc, cuda cache\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.5907091498374939\n",
      "loss:  0.3519069254398346\n",
      "loss:  0.07536350935697556\n",
      "loss:  0.04098983108997345\n",
      "loss:  0.030397765338420868\n",
      "loss:  0.026937702670693398\n",
      "loss:  0.023042790591716766\n",
      "loss:  0.018921643495559692\n",
      "loss:  0.015516463667154312\n",
      "loss:  0.012925740331411362\n",
      "loss:  0.010789918713271618\n",
      "loss:  0.008914338424801826\n",
      "loss:  0.007304217666387558\n",
      "loss:  0.006072200834751129\n",
      "loss:  0.0052165924571454525\n",
      "loss:  0.0046972911804914474\n",
      "loss:  0.004374220035970211\n",
      "loss:  0.004169862251728773\n",
      "loss:  0.0039529637433588505\n",
      "loss:  0.0037135060410946608\n",
      "loss:  0.003436537692323327\n",
      "loss:  0.003081295173615217\n",
      "loss:  0.0027440746780484915\n",
      "loss:  0.0023700143210589886\n",
      "loss:  0.002003422938287258\n",
      "loss:  0.001676481100730598\n",
      "loss:  0.001392290578223765\n",
      "loss:  0.0012092656688764691\n",
      "loss:  0.0011020827805623412\n",
      "loss:  0.0010656032245606184\n",
      "loss:  0.00105462153442204\n",
      "loss:  0.0010230487678200006\n",
      "loss:  0.000992905697785318\n",
      "loss:  0.000930040783714503\n",
      "loss:  0.000839955871924758\n",
      "loss:  0.0007376598077826202\n",
      "loss:  0.0006256058113649487\n",
      "loss:  0.0005613194080069661\n",
      "loss:  0.00047643447760492563\n",
      "loss:  0.0003980243927799165\n",
      "loss:  0.0003348467289470136\n",
      "loss:  0.00031853283871896565\n",
      "loss:  0.00031657476210966706\n",
      "loss:  0.0003181117644999176\n",
      "loss:  0.00030730071011930704\n",
      "loss:  0.0003019012219738215\n",
      "loss:  0.00029481668025255203\n",
      "loss:  0.0002982663281727582\n",
      "loss:  0.0003039158182218671\n",
      "loss:  0.00032308214576914907\n",
      "loss:  0.00033806447754614055\n",
      "loss:  0.0002950819325633347\n",
      "loss:  0.0002724899968598038\n",
      "loss:  0.00023029017029330134\n",
      "loss:  0.000232164456974715\n",
      "loss:  0.00023797183530405164\n",
      "loss:  0.00024569276138208807\n",
      "loss:  0.0002490167098585516\n",
      "loss:  0.00023051547759678215\n",
      "loss:  0.00020201863662805408\n",
      "loss:  0.00022925845405552536\n",
      "loss:  0.0003037294954992831\n",
      "loss:  0.0004118948127143085\n",
      "loss:  0.0005834187613800168\n",
      "loss:  0.0007566737476736307\n",
      "loss:  0.0008445556741207838\n",
      "loss:  0.0007834697025828063\n",
      "loss:  0.0006908637005835772\n",
      "loss:  0.0006744466372765601\n",
      "loss:  0.000797706306912005\n",
      "loss:  0.0009519875748082995\n",
      "loss:  0.0011109963525086641\n",
      "loss:  0.0012087223585695028\n",
      "loss:  0.0013502631336450577\n",
      "loss:  0.0014602064620703459\n",
      "loss:  0.0015329377492889762\n",
      "loss:  0.0013941029319539666\n",
      "loss:  0.0012074406258761883\n",
      "loss:  0.0009467100608162582\n",
      "loss:  0.0007305177859961987\n",
      "loss:  0.0006612055585719645\n",
      "loss:  0.000698300136718899\n",
      "loss:  0.0010505672544240952\n",
      "loss:  0.001062934985384345\n",
      "loss:  0.0011180243454873562\n",
      "loss:  0.0014377502957358956\n",
      "loss:  0.001696416991762817\n",
      "loss:  0.0018711341544985771\n",
      "loss:  0.0028927603270858526\n",
      "loss:  0.004028118681162596\n",
      "loss:  0.003694448620080948\n",
      "loss:  0.002602411201223731\n",
      "loss:  0.0021855977829545736\n",
      "loss:  0.001868239021860063\n",
      "loss:  0.0016188451554626226\n",
      "loss:  0.0016056268941611052\n",
      "loss:  0.0017570555210113525\n",
      "loss:  0.001943635637871921\n",
      "loss:  0.0020539031829684973\n",
      "loss:  0.0019187965663149953\n",
      "loss:  0.001605959958396852\n",
      "loss:  0.0013321927981451154\n",
      "loss:  0.001109198434278369\n",
      "loss:  0.000935358926653862\n",
      "loss:  0.0008135318639688194\n",
      "loss:  0.0007279040873982012\n",
      "loss:  0.0007366532227024436\n",
      "loss:  0.0008130999049171805\n",
      "loss:  0.0007541418890468776\n",
      "loss:  0.0006641960935667157\n",
      "loss:  0.0006368578760884702\n",
      "loss:  0.0006321906694211066\n",
      "loss:  0.000591774471104145\n",
      "loss:  0.0004995217313989997\n",
      "loss:  0.00043585116509348154\n",
      "loss:  0.0004254151717759669\n",
      "loss:  0.000491912302095443\n",
      "loss:  0.0005618021241389215\n",
      "loss:  0.0007391358376480639\n",
      "loss:  0.0006723149563185871\n",
      "loss:  0.0007301822188310325\n",
      "loss:  0.000844821915961802\n",
      "loss:  0.0007944662938825786\n",
      "loss:  0.0008095742668956518\n",
      "loss:  0.0009287642897106707\n",
      "loss:  0.0012396675301715732\n",
      "loss:  0.0013054037699475884\n",
      "loss:  0.0016428356757387519\n",
      "loss:  0.0021961319725960493\n",
      "loss:  0.002047004410997033\n",
      "loss:  0.0014661899767816067\n",
      "loss:  0.001598717411980033\n",
      "loss:  0.002607588190585375\n",
      "loss:  0.004426904022693634\n",
      "loss:  0.005618047434836626\n",
      "loss:  0.005760658532381058\n",
      "loss:  0.005173046141862869\n",
      "loss:  0.004266935866326094\n",
      "loss:  0.0034658557269722223\n",
      "loss:  0.002706122351810336\n",
      "loss:  0.0021887030452489853\n",
      "loss:  0.0017712913686409593\n",
      "loss:  0.0017576050013303757\n",
      "loss:  0.0021568341180682182\n",
      "loss:  0.0024903430603444576\n",
      "loss:  0.0026681353338062763\n",
      "loss:  0.0027190071996301413\n",
      "loss:  0.002949790097773075\n",
      "loss:  0.0031000180169939995\n",
      "loss:  0.0029156391974538565\n",
      "loss:  0.002575684804469347\n",
      "loss:  0.0021262764930725098\n",
      "loss:  0.0015093302354216576\n",
      "loss:  0.0010885666124522686\n",
      "loss:  0.0012292350875213742\n",
      "loss:  0.0010651620104908943\n",
      "loss:  0.0011266195215284824\n",
      "loss:  0.0013847212539985776\n",
      "loss:  0.0017129563493654132\n",
      "loss:  0.002000549342483282\n",
      "loss:  0.0019625972490757704\n",
      "loss:  0.0016699539264664054\n",
      "loss:  0.00130390003323555\n",
      "loss:  0.0009264604886993766\n",
      "loss:  0.0006286199204623699\n",
      "loss:  0.00044715209514833987\n",
      "loss:  0.0003881514130625874\n",
      "loss:  0.0004372771654743701\n",
      "loss:  0.0005319867632351816\n",
      "loss:  0.0006101706530898809\n",
      "loss:  0.0006890084478072822\n",
      "loss:  0.000752084597479552\n",
      "loss:  0.0007839747122488916\n",
      "loss:  0.0008123517036437988\n",
      "loss:  0.000792277161963284\n",
      "loss:  0.0008758499170653522\n",
      "loss:  0.0008485353901050985\n",
      "loss:  0.0007418090244755149\n",
      "loss:  0.0006311346078291535\n",
      "loss:  0.0005882109981030226\n",
      "loss:  0.000655311334412545\n",
      "loss:  0.0007540325168520212\n",
      "loss:  0.0009396102395839989\n",
      "loss:  0.0010592812905088067\n",
      "loss:  0.001141561078839004\n",
      "loss:  0.0011094745714217424\n",
      "loss:  0.001046247431077063\n",
      "loss:  0.0008415883639827371\n",
      "loss:  0.0008584914612583816\n",
      "loss:  0.0009572888957336545\n",
      "loss:  0.0007522721425630152\n",
      "loss:  0.0005150383221916854\n",
      "loss:  0.0005904739955440164\n",
      "loss:  0.0007711909711360931\n",
      "loss:  0.000834459497127682\n",
      "loss:  0.0007651891210116446\n",
      "loss:  0.0007853370043449104\n",
      "loss:  0.0008415345218963921\n",
      "loss:  0.0009891015943139791\n",
      "loss:  0.0010350242955610156\n",
      "loss:  0.0016914638690650463\n",
      "loss:  0.002295680809766054\n",
      "loss:  0.0020980238914489746\n",
      "loss:  0.0014370144344866276\n",
      "loss:  0.0009845129679888487\n",
      "loss:  0.0011942611308768392\n",
      "loss:  0.003064914373680949\n",
      "loss:  0.0024625614751130342\n",
      "loss:  0.0018343719420954585\n",
      "loss:  0.0016314140520989895\n",
      "loss:  0.0016939230263233185\n",
      "loss:  0.001772552845068276\n",
      "loss:  0.001578406780026853\n",
      "loss:  0.001192248659208417\n",
      "loss:  0.0009451809455640614\n",
      "loss:  0.0009363216231577098\n",
      "loss:  0.0009620970231480896\n",
      "loss:  0.0008996172691695392\n",
      "loss:  0.0008109068148769438\n",
      "loss:  0.0007111888262443244\n",
      "loss:  0.0006691068992950022\n",
      "loss:  0.0006418416160158813\n",
      "loss:  0.0006303612026385963\n",
      "loss:  0.0007471907883882523\n",
      "loss:  0.0035792638082057238\n",
      "loss:  0.003519155317917466\n",
      "loss:  0.001331732957623899\n",
      "loss:  0.0009514727280475199\n",
      "loss:  0.0011416040360927582\n",
      "loss:  0.0014622460585087538\n",
      "loss:  0.0015501213492825627\n",
      "loss:  0.0014047836884856224\n",
      "loss:  0.0011503647547215223\n",
      "loss:  0.001113213482312858\n",
      "loss:  0.001063232310116291\n",
      "loss:  0.001238219323568046\n",
      "loss:  0.0017162447329610586\n",
      "loss:  0.002500900300219655\n",
      "loss:  0.0032130505423992872\n",
      "loss:  0.0025905808433890343\n",
      "loss:  0.002151747699826956\n",
      "loss:  0.0026899510994553566\n",
      "loss:  0.004419165197759867\n",
      "loss:  0.005931569263339043\n",
      "loss:  0.006542403716593981\n",
      "loss:  0.005830134265124798\n",
      "loss:  0.004859376233071089\n",
      "loss:  0.0032874036114662886\n",
      "loss:  0.002331513911485672\n",
      "loss:  0.0021089576184749603\n",
      "loss:  0.0024263905361294746\n",
      "loss:  0.002872051438316703\n",
      "loss:  0.0033919832203537226\n",
      "loss:  0.003673508297652006\n",
      "loss:  0.0038058601785451174\n",
      "loss:  0.0035408891271799803\n",
      "loss:  0.0031183790415525436\n",
      "loss:  0.0024998383596539497\n",
      "loss:  0.0017369543202221394\n",
      "loss:  0.0011763187358155847\n",
      "loss:  0.0011122208088636398\n",
      "loss:  0.0011496866354718804\n",
      "loss:  0.0014486904256045818\n",
      "loss:  0.0017009122529998422\n",
      "loss:  0.001882788841612637\n",
      "loss:  0.0017840627115219831\n",
      "loss:  0.0015120893949642777\n",
      "loss:  0.001141799264587462\n",
      "loss:  0.0007859925972297788\n",
      "loss:  0.0005702033522538841\n",
      "loss:  0.0004905731766484678\n",
      "loss:  0.0005071648047305644\n",
      "loss:  0.0005835270858369768\n",
      "loss:  0.000666947802528739\n",
      "loss:  0.0006876767729409039\n",
      "loss:  0.0006269222358241677\n",
      "loss:  0.0005045303259976208\n",
      "loss:  0.00039530560025013983\n",
      "loss:  0.00028095589368604124\n",
      "loss:  0.0002193456020904705\n",
      "loss:  0.00021660738275386393\n",
      "loss:  0.0002723624638747424\n",
      "loss:  0.00033015868393704295\n",
      "loss:  0.0003243249375373125\n",
      "loss:  0.00029107555747032166\n",
      "loss:  0.00024302941164933145\n",
      "loss:  0.00017902486433740705\n",
      "loss:  0.00014960899716243148\n",
      "loss:  0.00013651285553351045\n",
      "loss:  0.00013536072219721973\n",
      "loss:  0.00015913289098534733\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Brandon\\Documents\\Pose Detection\\simplepose\\train_vivit.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Brandon/Documents/Pose%20Detection/simplepose/train_vivit.ipynb#W1sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     history\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Brandon/Documents/Pose%20Detection/simplepose/train_vivit.ipynb#W1sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Brandon/Documents/Pose%20Detection/simplepose/train_vivit.ipynb#W1sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39mprint\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mloss: \u001b[39;49m\u001b[39m\"\u001b[39;49m, loss\u001b[39m.\u001b[39;49mitem())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Brandon/Documents/Pose%20Detection/simplepose/train_vivit.ipynb#W1sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mprint\u001b[39m(video_loss\u001b[39m/\u001b[39m(num_frames\u001b[39m-\u001b[39mvivit_num_frames\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = []\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "model.train()\n",
    "for i, v in enumerate(train_loader):\n",
    "    #sliding window of 32 frames or less, if we are at the beginning\n",
    "    \n",
    "    all_frames = v[0]/255.0\n",
    "    num_frames = all_frames.shape[1]\n",
    "    labels = v[1]\n",
    "    labels = labels.to(device)\n",
    "    video_loss = 0\n",
    "    # if len(v[0]) < 32:\n",
    "    #     continue\n",
    "    for j in range(vivit_num_frames-1, num_frames):\n",
    "        start_range =  (j-(vivit_num_frames-1))\n",
    "        if start_range < 0:\n",
    "            break\n",
    "        end_range = j+1\n",
    "        # v is [batch, frames, height, width, channels]\n",
    "        frames = all_frames[:,start_range:end_range].detach().clone()\n",
    "        #convert frames to byte tensor\n",
    "        frames = frames.to(device)\n",
    "        frames = frames.permute(0,1,4,2,3)\n",
    "        output = model(frames)\n",
    "        label = labels[:,j]\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        video_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        history.append(loss.item())\n",
    "        torch.cuda.empty_cache()\n",
    "    print(video_loss/(num_frames-vivit_num_frames+1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
