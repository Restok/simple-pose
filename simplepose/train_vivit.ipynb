{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brandon\\miniconda3\\envs\\mldl\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import VivitConfig\n",
    "\n",
    "from model.vivit import VivitPose\n",
    "from preprocess_data import get_video_datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "device = 'cuda'\n",
    "configuration = VivitConfig()\n",
    "vivit_num_frames = 5\n",
    "configuration.num_labels = 201\n",
    "configuration.num_frames=vivit_num_frames\n",
    "model = VivitPose(configuration).to(device)\n",
    "train_data, test_data = get_video_datasets()\n",
    "train_loader = DataLoader(train_data, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear gc, cuda cache\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read data\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 201])\n",
      "trying\n",
      "torch.Size([1, 393, 768])\n",
      "torch.Size([1, 393, 768])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Brandon\\Documents\\Pose Detection\\simplepose\\train_vivit.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Brandon/Documents/Pose%20Detection/simplepose/train_vivit.ipynb#W1sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m frames \u001b[39m=\u001b[39m frames\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Brandon/Documents/Pose%20Detection/simplepose/train_vivit.ipynb#W1sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m frames \u001b[39m=\u001b[39m frames\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m4\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Brandon/Documents/Pose%20Detection/simplepose/train_vivit.ipynb#W1sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m output \u001b[39m=\u001b[39m model(frames)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Brandon/Documents/Pose%20Detection/simplepose/train_vivit.ipynb#W1sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(output\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Brandon/Documents/Pose%20Detection/simplepose/train_vivit.ipynb#W1sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n",
      "File \u001b[1;32mc:\\Users\\Brandon\\miniconda3\\envs\\mldl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Brandon\\Documents\\Pose Detection\\simplepose\\model\\vivit.py:757\u001b[0m, in \u001b[0;36mVivitPose.forward\u001b[1;34m(self, pixel_values, head_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    745\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    746\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    747\u001b[0m     pixel_values: Optional[torch\u001b[39m.\u001b[39mFloatTensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    752\u001b[0m     return_dict: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    753\u001b[0m ):\n\u001b[0;32m    755\u001b[0m     return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m--> 757\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvivit(\n\u001b[0;32m    758\u001b[0m         pixel_values,\n\u001b[0;32m    759\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    760\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    761\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m    762\u001b[0m         return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m    763\u001b[0m     )\n\u001b[0;32m    765\u001b[0m     sequence_output \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    767\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier(sequence_output[:, \u001b[39m0\u001b[39m, :])\n",
      "File \u001b[1;32mc:\\Users\\Brandon\\miniconda3\\envs\\mldl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Brandon\\Documents\\Pose Detection\\simplepose\\model\\vivit.py:561\u001b[0m, in \u001b[0;36mVivitModel.forward\u001b[1;34m(self, pixel_values, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    557\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    559\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(pixel_values)\n\u001b[1;32m--> 561\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[0;32m    562\u001b[0m     embedding_output,\n\u001b[0;32m    563\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    564\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    565\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m    566\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m    567\u001b[0m )\n\u001b[0;32m    568\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    569\u001b[0m sequence_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayernorm(sequence_output)\n",
      "File \u001b[1;32mc:\\Users\\Brandon\\miniconda3\\envs\\mldl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Brandon\\Documents\\Pose Detection\\simplepose\\model\\vivit.py:332\u001b[0m, in \u001b[0;36mVivitEncoder.forward\u001b[1;34m(self, hidden_states, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    325\u001b[0m     layer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    326\u001b[0m         layer_module\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[0;32m    327\u001b[0m         hidden_states,\n\u001b[0;32m    328\u001b[0m         layer_head_mask,\n\u001b[0;32m    329\u001b[0m         output_attentions,\n\u001b[0;32m    330\u001b[0m     )\n\u001b[0;32m    331\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 332\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(hidden_states, layer_head_mask, output_attentions)\n\u001b[0;32m    334\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    336\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32mc:\\Users\\Brandon\\miniconda3\\envs\\mldl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Brandon\\Documents\\Pose Detection\\simplepose\\model\\vivit.py:290\u001b[0m, in \u001b[0;36mVivitLayer.forward\u001b[1;34m(self, hidden_states, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39m# in Vivit, layernorm is also applied after self-attention\u001b[39;00m\n\u001b[0;32m    289\u001b[0m layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayernorm_after(hidden_states)\n\u001b[1;32m--> 290\u001b[0m layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintermediate(layer_output)\n\u001b[0;32m    292\u001b[0m \u001b[39m# second residual connection is done here\u001b[39;00m\n\u001b[0;32m    293\u001b[0m layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(layer_output, hidden_states)\n",
      "File \u001b[1;32mc:\\Users\\Brandon\\miniconda3\\envs\\mldl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Brandon\\Documents\\Pose Detection\\simplepose\\model\\vivit.py:239\u001b[0m, in \u001b[0;36mVivitIntermediate.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states):\n\u001b[0;32m    238\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdense(hidden_states)\n\u001b[1;32m--> 239\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintermediate_act_fn(hidden_states)\n\u001b[0;32m    240\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m    242\u001b[0m     \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32mc:\\Users\\Brandon\\miniconda3\\envs\\mldl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Brandon\\miniconda3\\envs\\mldl\\lib\\site-packages\\transformers\\activations.py:87\u001b[0m, in \u001b[0;36mFastGELUActivation.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m---> 87\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m \u001b[39minput\u001b[39m \u001b[39m*\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39mtanh(\u001b[39minput\u001b[39;49m \u001b[39m*\u001b[39;49m \u001b[39m0.7978845608\u001b[39;49m \u001b[39m*\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m+\u001b[39m \u001b[39m0.044715\u001b[39m \u001b[39m*\u001b[39m \u001b[39minput\u001b[39m \u001b[39m*\u001b[39m \u001b[39minput\u001b[39m)))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = []\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "model.train()\n",
    "for i, v in enumerate(train_loader):\n",
    "    #sliding window of 32 frames or less, if we are at the beginning\n",
    "    \n",
    "    all_frames = v[0]/255.0\n",
    "    num_frames = all_frames.shape[1]\n",
    "    labels = v[1]\n",
    "    \n",
    "    # if len(v[0]) < 32:\n",
    "    #     continue\n",
    "    for j in range(vivit_num_frames-1, num_frames):\n",
    "        start_range =  (j-(vivit_num_frames-1))\n",
    "        if start_range < 0:\n",
    "            break\n",
    "        end_range = j+1\n",
    "        # v is [batch, frames, height, width, channels]\n",
    "        frames = all_frames[:,start_range:end_range].detach().clone()\n",
    "        #convert frames to byte tensor\n",
    "        frames = frames.to(device)\n",
    "        frames = frames.permute(0,1,4,2,3)\n",
    "        output = model(frames)\n",
    "        \n",
    "        print(output.shape)\n",
    "        torch.cuda.empty_cache()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
